% =============================================================================
% FILE NAME : 02_related_work.tex
% DEPARTMENT: University of Tuebingen
% AUTOR     : Tom Schammo
% =============================================================================
% CONTENT   : Include for chapter "Related Work"
% =============================================================================

\section{Rust on the PULPissimo}

The code in this thesis is built upon the foundations built by Raphael Vogelgsang in his thesis \emph{'Rust auf der RISCV Plattform PULPissimo – Entwicklung und
Evaluation'} \cite{rust_pulp}.
He built the PAC and HAL which is used and extended to add support for the UltraTrail architecture.
The PAC provides direct access to peripherals and has been generated using the '\lstinline{svd2rust}' tool \cite{svd2rust}.
This tool uses a System View Description (SVD) file, which uses the XML format to describe certain properties like registers and peripherals, and are
thereby unique for each microcontroller.
SVD files are usually provided by the vendor, but in this case, it had to be written from scratch.
The HAL builds upon the PAC and provides a layer of abstraction between the programmer and the hardware.
It implements a user-friendly API that removes the need for detailed knowledge about the hardware architecture.

\section{Previous work on the PULPissimo}

The chair for embedded systems has developed some C libraries for the PULPissimo that provide drivers and tests.
They serve as an orientation and comparison for the Rust libraries.

\section{UltraTrail}

UltraTrail is a 'configurable ultra-low power TC-ResNet AI accelerator for efficient keyword spotting' \cite{ultratrail}.
It uses temporal convolutional networks (TCNs) combined with residual networks (TC-ResNet) for intelligent sensor signal processing.
They show superior behavior compared to conventional convolutional neural networks (CNNs) and long short-term memory (LSTM) networks,
which are a type of Recurrent Neural Network (RNN), and are commonly in used speech recognition applications like keyword-spotting or text-to-speech engines.
TCNs specifically not only appear to be more accurate but also more simple and clear compared to LSTMs and GRUs \cite[Ch I]{ultratrail}.\\
UltraTrail uses a variety of units, arrays, and layers to provide efficient mapping of the TC-ResNet without sacrificing too much flexibility.
It can execute networks with up to 16 convolutional layers that can be extended with batch normalization (also referred to as CONV-EXT layers)
and uses 6-bit weights and 8-bit feature inputs.\\
The network model is saved in the weight memory (WMEM) and bias memory (BMEM), which
have a capacity of 64 kB and 512 Bytes respectively.
UltraTrail is also equipped with three feature map memories (FMEM) to store input and output
feature maps. The inputs are stored in FMEM0 while any outputs are written to FMEM1 and FMEM2.
These five memories surround the 8 by 8 MAC array with local memory (LMEM) and the Output Processing Unit (OPU) as displayed in Figure~\ref{fig:ultratrail_arch}.
\begin{figure}[htb]
    \centering
    \includegraphics[width=0.9\textwidth]{figures/ultratrail.png}
    \caption[Illustration: The UltraTrail system architecture (Fig. 5)\cite{ultratrail}]{The UltraTrail system architecture}
    \label{fig:ultratrail_arch}
\end{figure}
\\\\
The MAC array is the primary processing unit and enables convolutional computation.
It contains 64 MAC units that are arranged in an 8 by 8 grid that uses the LMEM to store partial sums during computation.
The size of the array allows for almost optimal utilization of the available processing units due to the structure of the
neural network that runs on UltraTrail.
The greatest common divisor of the number of outputs in the output layers is 8, therefore an 8 by 8 grid of mac units
allows optimal parallelization with full utilization of the available resources.
Different numbers of MAC units would lead to certain rows of the grid not being used during at least some stages of the
computation process.
While other combinations would work as well (like 4 by 4), 8 by 8 seems to be the optimal trade-off when
considering execution speed, and power consumption.
\\
The OPU receives the output features generated by the MAC array and combines bias, ReLU activation,
average pooling and condition computing to complete the remaining post-processing steps.
The results are written back to FMEM.
\\
UltraTrail additionally has a programmable control unit that contains a 672 bit
configuration register, which is big enough so that the network structure
can be described layer by layer \cite[Ch IV]{ultratrail}.

\newpage
\section{Keyword spotting in the Industry}

\subsection{Voice Assistants}

Keyword spotting is mainly used in voice assistants (VAs), like Siri, which is developed by Apple \cite{siri}, or Amazon's Alexa \cite{alexa}.
The devices they run on (like the Amazon Echo Dot or the Apple iPhone) use keyword-spotting to 'activate', after which they start
to 'actively listen' to perform your command.
There are also open-source alternatives to the popular products by the aforementioned tech giants, like Mycroft by \lstinline{mycroft.ai} \cite{mycroft}.
Snips.ai used to be another alternative VA to the products by Apple and Amazon, however, they have been acquired by Sonos in November 2019 \cite{sonos_snips}.
Snips also used keyword-spotting to 'activate' the VA that the user could then communicate with, however, they also advertised their focus
on privacy and offline, on-device speech processing.
However, their product was not open source, so there is limited knowledge available about their system.
They do advertise customizable 'wake words' and mentioned hardware requirements on a snapshot of their website \cite{snips_flow}.
It was possible to run their system on devices like the Raspberry Pi 3 \cite{rpi3} or Jetson TX2 \cite{jetson_tx2},
as well as the Snapdragon 410 \cite{snapdragon_410} by Qualcomm, which had been used in phones like the Samsung Galaxy J5 or Xiaomi Redmi 2.
Since there is not a lot of public knowledge available for proprietary systems like Siri, Alexa, or Snips, I will only take a more in-depth look at Mycroft.

\subsubsection{Mycroft}

Mycroft is an open source \cite{mycroft_gh} and privacy-focused VA \cite{mycroft}.
It runs a variety of devices like the Raspberry Pi, common desktop devices, but also custom hardware, the manufacturer claims.
Like Alexa, Mycroft can be extended by adding skills \cite{mycroft_skills}, which can either be acquired for free on their marketplace,
from GitHub, or self-made.\\\\
Mycroft consists of several technologies; 'Mimic' \cite{mycroft_mimic3}, their text-to-speech engine, 'Adapt' \cite{mycroft_adapt} and 'Padatious' \cite{mycroft_padatious},
their intent parsers for natural language understanding, and most interestingly for this thesis, 'Precise' \cite{mycroft_precise} their wake word listener.\\
Precise uses a type of RNN, a Grated Recurrent Unit (GRU), illustrated in Figure~\ref{fig:precise_gru}.
Once the raw audio data is handed over to Precise it is split into chunks.
MFCC features are then calculated from these chunks, which are handed over to the GRU.
After a dense layer at the end, the GRU can predict for each chunk, whether it contains the keyword or not.


\begin{figure}[htb]
    \centering
    \includegraphics[width=0.9\textwidth]{figures/precise_engine.PNG}
    \caption[Illustration: The 'Precise' engine \cite{mycroft_precise}]{The 'Precise' engine illustrated}
    \label{fig:precise_gru}
\end{figure}
